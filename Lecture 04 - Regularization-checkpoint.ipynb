{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation and Training, Validation, Testing Data Sets\n",
    "\n",
    "* Since we can (often, easily) overfit, our error or prediction performance on a training data set is not a good indication of performance on unknown test data.  \n",
    "* One way estimate test performance of a system on unknown test data is to use some of the training data for training and some for validation (to act like unknown test data). \n",
    "* If you are repeatedly changing your model/adjusting parameters/tweaking your algorithm, you may even over fit the hold-out validation set.  So, you can hold out yet another set for testing. \n",
    "* However, in general, we only have a limited amount of training data. So, we want to use as much of it as possible for training.  One strategy to balance the tradeoff between needing training data and validation data is to use cross-validation.\n",
    "* Cross-validation can also give an indication of stability/robustness of your method. \n",
    "* However there are downsides to cross-validation: need to train many times (which can sometimes be very computationally complex.), and you end up with several models - how do you pick the final one to use?\n",
    " \n",
    "* For further reading and reference: Simon Haykin. Neural Networks A Comprehensive Foundation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Two common approaches to avoid overfitting:\n",
    "    1. More data: As you have more and more data, it becomes more and more difficult to ``memorize'' the data and its noise. Often, more data translates to the ability to use a more complex model and avoid overfitting.  However, generally, you need exponentially more data with increases to model complexity.  So, there is a limit to how much this helps.  If you have a very complex model, you need a huge training data set. \n",
    "    2. Regularization: Regularization methods add a penalty term to the error function to discourage overfitting.  These penalty terms encourage small values limiting the ability to overfit.   These penalty terms are a way to trade-off between error and complexity.  \n",
    "\n",
    "\n",
    "\\begin{eqnarray}\n",
    "E^{\\ast}(\\mathbf{w}) &=& \\frac{1}{2}\\sum_{n=1}^N \\left( y(x_n, \\mathbf{w}) - t_n \\right)^2 + \\frac{\\lambda}{2}\\left\\| \\mathbf{w} \\right\\|^2_2\\\\\n",
    "&=& \\frac{1}{2}\\left(\\mathbf{w}^T\\mathbf{X}^T - \\mathbf{t}^T\\right)\\left(\\mathbf{w}^T\\mathbf{X}^T - \\mathbf{t}^T\\right)^T + \\frac{\\lambda}{2}\\mathbf{w}^T\\mathbf{w}\\\\\n",
    "&=& \\frac{1}{2}\\left\\| \\mathbf{w}^T\\mathbf{X}^T - \\mathbf{t}^T\\right\\|_2^2 + \\frac{\\lambda}{2}\\left\\| \\mathbf{w}\\right\\|_2^2\n",
    "\\end{eqnarray}\n",
    "\n",
    "* *What does each term mean/promote in the minimization? Why does the second term make sense for minimizing complexity?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{eqnarray}\n",
    "E^{\\ast}(\\mathbf{w}) &=& \\frac{1}{2}\\sum_{n=1}^N \\left( y(x_n, \\mathbf{w}) - t_n \\right)^2 + \\frac{\\lambda}{2}\\left\\| \\mathbf{w} \\right\\|^2_2\\\\\n",
    "&=& \\frac{1}{2}\\left(\\mathbf{w}^T\\mathbf{X}^T - \\mathbf{t}^T\\right)\\left(\\mathbf{w}^T\\mathbf{X}^T - \\mathbf{t}^T\\right)^T + \\frac{\\lambda}{2}\\mathbf{w}^T\\mathbf{w}\n",
    "\\end{eqnarray}\n",
    "\\begin{eqnarray}\n",
    "& &\\frac{\\partial E^{\\ast}(\\mathbf{w})}{\\partial \\mathbf{w}} = 0 = \\mathbf{X}^T\\left(\\mathbf{w}^T\\mathbf{X}^T - \\mathbf{t}^T\\right)^T + \\frac{\\lambda}{2}2 \\mathbf{w}\\\\\n",
    "& & 0 = \\mathbf{X}^T\\mathbf{X}\\mathbf{w} - \\mathbf{X}^T\\mathbf{t} + \\lambda\\mathbf{w}\\\\\n",
    "& & \\mathbf{X}^T\\mathbf{t} = \\left(\\mathbf{X}^T\\mathbf{X} + \\lambda\\mathbf{I} \\right)\\mathbf{w}\\\\\n",
    "& & \\mathbf{w} = \\left(\\mathbf{X}^T\\mathbf{X} + \\lambda\\mathbf{I} \\right)^{-1}\\mathbf{X}^T\\mathbf{t}\n",
    "\\end{eqnarray}\n",
    "\n",
    "* The $l_2$ norm penalty is common (because it works so well mathematically with the least-squares error objective) and, so, has many names: shrinkage, ridge regression, weight decay\n",
    "\n",
    "* *So, what happens when $\\lambda$ is increased? decreased?  Can you think of a way to set $\\lambda$?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math \n",
    "import matplotlib.pyplot as plt\n",
    "import textwrap\n",
    "%matplotlib inline \n",
    "\n",
    "def generateUniformData(N, l, u, gVar):\n",
    "\t'''generateUniformData(N, l, u, gVar): Generate N uniformly spaced data points \n",
    "    in the range [l,u) with zero-mean Gaussian random noise with standard deviation gVar'''\n",
    "\t# x = np.random.uniform(l,u,N)\n",
    "\tstep = (u-l)/(N)\n",
    "\tx = np.arange(l+step/2,u+step/2,step)\n",
    "\te = np.random.normal(0,gVar,N)\n",
    "\tt = np.sin(2*math.pi*x) + e\n",
    "\treturn x,t\n",
    "\n",
    "\n",
    "def plotData(x1,t1,x2,t2,x3=None,t3=None,legend=[]):\n",
    "    #plot everything\n",
    "    p1 = plt.plot(x1, t1, 'bo') #plot training data\n",
    "    p2 = plt.plot(x2, t2, 'g') #plot true value\n",
    "    if(x3 is not None):\n",
    "        p3 = plt.plot(x3, t3, 'r') \n",
    "\n",
    "    #add title, legend and axes labels\n",
    "    plt.ylabel('t') #label x and y axes\n",
    "    plt.xlabel('x')\n",
    "    \n",
    "    if(x3 is None):\n",
    "        plt.legend((p1[0],p2[0]),legend)\n",
    "    else:\n",
    "        plt.legend((p1[0],p2[0],p3[0]),legend)\n",
    "\n",
    "def fitdataReg(x,t,M,la):\n",
    "\t'''fitdata(x,t,M): Fit a polynomial of order M to the data (x,t)'''\t\n",
    "\tX = np.array([x**m for m in range(M+1)]).T\n",
    "\tw = np.linalg.inv(X.T@X+(la*np.identity(M+1)))@X.T@t\n",
    "\treturn w\n",
    "        \n",
    "l = 0\n",
    "u = 1\n",
    "N = 10\n",
    "gVar = .1\n",
    "\n",
    "data_uniform  = np.array(generateUniformData(N, l, u, gVar)).T\n",
    "x1 = data_uniform[:,0]\n",
    "t1 = data_uniform[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = 9\n",
    "la = 0\n",
    "fig = plt.figure()\n",
    "\n",
    "w = fitdataReg(x1,t1,M,la)\n",
    "\n",
    "x2 = np.arange(l,u,0.001)  #get equally spaced points in the xrange\n",
    "t2 = np.sin(2*math.pi*x2) #compute the true function value\n",
    "    \n",
    "X3 = np.array([x2**m for m in range(M+1)]).T\n",
    "x3 = x2\n",
    "t3 = X3@w\n",
    "\n",
    "plotData(x1, t1, x2, t2, x3, t3, legend=['Training Data', 'True Function', 'Estimated Function'])\n",
    "print(w)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Bayesian Interpretation of Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "* We looked at the regularization term as a *penalty* term in the objective function.  There is another way to interpret the regularization term as well.  Specifically, there is a *Bayesian* interpretation. \n",
    "\n",
    "\\begin{eqnarray}\n",
    "\\min E^{\\ast}(\\mathbf{w}) &=& \\max -E^{\\ast}(\\mathbf{w})\\\\\n",
    "& =& \\max \\exp \\left\\{ -E^{\\ast}(\\mathbf{w})\\right\\}\\\\\n",
    "&=& \\max \\exp \\left\\{ -\\frac{1}{2}\\sum_{n=1}^N \\left( y(x_n, \\mathbf{w}) - t_n \\right)^2 - \\frac{\\lambda}{2}\\left\\| \\mathbf{w} \\right\\|^2_2 \\right\\}\\\\\n",
    "&=& \\max \\exp \\left\\{ -\\frac{1}{2}\\sum_{n=1}^N \\left( y(x_n, \\mathbf{w}) - t_n \\right)^2 \\right\\}\\exp\\left\\{-\\frac{1}{2}\\lambda\\left\\| \\mathbf{w} \\right\\|^2_2\\right\\}\\\\\n",
    "&=& \\max \\prod_{n=1}^N \\exp \\left\\{ -\\frac{1}{2} \\left( y(x_n, \\mathbf{w}) - t_n \\right)^2 \\right\\}\\exp\\left\\{-\\frac{1}{2}\\lambda\\left\\| \\mathbf{w} \\right\\|^2_2\\right\\}\n",
    "\\end{eqnarray}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* So, this is a maximization of the *data likelihood* with a *prior*: $p(\\mathbf{X}|\\mathbf{w})p(\\mathbf{w})$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method of Maximum Likelihood\n",
    "\n",
    "* A *data likelihood* is how likely the data is given the parameter set\n",
    "* So, if we want to maximize how likely the data is to have come from the model we fit, we should find the parameters that maximize the likelihood\n",
    "* A common trick of maximizing the likelihood is to maximize the log likelihood.  Often makes the math much easier.  *Why can we maximize the log likelihood instead of the likelihood and still get the same answer?*\n",
    "* Consider: $\\max \\ln \\exp \\left\\{ -\\frac{1}{2}\\left(y(x_n, \\mathbf{w}) - t_n\\right)^2\\right\\}$ We go back to our original objective. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method of Maximum A Posteriori (MAP)\n",
    "\n",
    "* Bayes Rule: $p(Y|X) = \\frac{p(X|Y)p(Y)}{p(X)}$\n",
    "* Consider: $p(\\mathbf{w}|\\mathscr{D}) = \\frac{p(\\mathscr{D}|\\mathbf{w})p(\\mathbf{w})}{p(\\mathscr{D})}$, i.e., posterior $\\propto$ likelihood $\\times$ prior\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
